# Video2Markdown æ¶æ„è®¾è®¡

> ğŸ“‹ è¯¦ç»†å¤„ç†æµç¨‹è¯·æŸ¥çœ‹ [WORKFLOW.md](./WORKFLOW.md)

## 1. ç³»ç»Ÿæ¶æ„

```mermaid
flowchart TD
    Input[è¾“å…¥è§†é¢‘]
    
    subgraph Stage1 [Stage 1: è§†é¢‘åˆ†æ]
        S1A[FFmpeg è¯»å–å…ƒæ•°æ®]
        S1B[OpenCV åœºæ™¯æ£€æµ‹]
    end
    
    subgraph Stage2 [Stage 2: éŸ³é¢‘è½¬å½• + M1]
        S2A[FFmpeg æå–éŸ³é¢‘]
        S2B[Whisper è¯­éŸ³è½¬å½•]
        S2C[OpenCC ç¹ç®€è½¬æ¢]
        S2D[AI ä¼˜åŒ–ä¸ºå¯è¯»æ–‡ç¨¿]
    end
    
    subgraph Stage3 [Stage 3: å…³é”®å¸§æå–]
        S3A[åœºæ™¯å˜åŒ–æ—¶é—´ç‚¹]
        S3B[å›ºå®šé—´éš”è¡¥å……]
    end
    
    subgraph Stage4 [Stage 4: æ™ºèƒ½ç­›é€‰ = M2]
        S4A[OCR æ–‡å­—æ£€æµ‹]
        S4B[è¯­ä¹‰ç›¸å…³æ€§æ£€æŸ¥]
        S4C[è§†è§‰è´¨é‡è¯„ä¼°]
    end
    
    subgraph Stage5 [Stage 5: AI å›¾åƒåˆ†æ = M3]
        S5A[æå–åŸå§‹å¸§]
        S5B[Kimi Vision åˆ†æ]
        S5C[ç”Ÿæˆå›¾ç‰‡æè¿°]
    end
    
    subgraph Stage6 [Stage 6: å›¾æ–‡èåˆ]
        S6A[åˆ†æ M1 ç»“æ„]
        S6B[åŒ¹é… M2/M3 é…å›¾]
        S6C[ç”Ÿæˆç« èŠ‚ç»“æ„]
    end
    
    subgraph Stage7 [Stage 7: Markdown æ¸²æŸ“]
        S7A[æ¸²æŸ“æœ€ç»ˆæ–‡æ¡£]
        S7B[ä¿å­˜é…å›¾æ–‡ä»¶]
    end
    
    Input --> Stage1
    Stage1 --> Stage2
    Stage1 --> Stage3
    Stage2 --> M1[M1: AIä¼˜åŒ–æ–‡ç¨¿]
    Stage2 --> Stage4
    Stage3 --> Stage4
    Stage4 --> M2[M2: ç­›é€‰åå…³é”®å¸§]
    M1 --> Stage5
    M2 --> Stage5
    Stage5 --> M3[M3: é…å›¾è¯´æ˜]
    M1 --> Stage6
    M2 --> Stage6
    M3 --> Stage6
    Stage6 --> Stage7
    Stage7 --> Output[æœ€ç»ˆ Markdown]
```

## 2. æ¨¡å—ç»“æ„

### 2.1 Stage æ¨¡å—ï¼ˆæ ¸å¿ƒå¤„ç†ï¼‰

| æ–‡ä»¶ | åŠŸèƒ½ | è¾“å…¥ | è¾“å‡º |
|------|------|------|------|
| `stage1_analyze.py` | è§†é¢‘åˆ†æ | è§†é¢‘æ–‡ä»¶ | `VideoInfo` |
| `stage2_transcribe.py` | éŸ³é¢‘è½¬å½• + AIä¼˜åŒ– | è§†é¢‘ + `VideoInfo` | `VideoTranscript` (M1) |
| `stage3_keyframes.py` | å…³é”®å¸§æå– | è§†é¢‘ + `VideoInfo` | `KeyFrames` (å€™é€‰) |
| `stage4_filter.py` | æ™ºèƒ½å›¾ç‰‡ç­›é€‰ | `KeyFrames` + M1 | `KeyFrames` (M2) |
| `stage5_analyze_images.py` | AIå›¾åƒåˆ†æ | M1 + M2 | `ImageDescriptions` (M3) |
| `stage6_generate.py` | å›¾æ–‡èåˆ | M1 + M2 + M3 | `Document` |
| `stage7_render.py` | Markdownæ¸²æŸ“ | `Document` + M1 + M3 | `.md` æ–‡ä»¶ |

### 2.2 æ”¯æŒæ¨¡å—

| æ–‡ä»¶ | åŠŸèƒ½ |
|------|------|
| `cli.py` | å‘½ä»¤è¡Œæ¥å£ï¼Œå®šä¹‰ `stage1`~`stage6` å’Œ `process` å‘½ä»¤ |
| `config.py` | é…ç½®ç®¡ç†ï¼ˆç¯å¢ƒå˜é‡ã€.envã€è·¯å¾„è§£æï¼‰ |
| `models.py` | æ•°æ®æ¨¡å‹ï¼ˆ`VideoInfo`, `TranscriptSegment`, `KeyFrame`, ç­‰ï¼‰ |

## 3. æ•°æ®æ¨¡å‹

### 3.1 æ ¸å¿ƒæ¨¡å‹

```python
@dataclass
class VideoInfo:
    path: Path
    duration: float          # ç§’
    width: int
    height: int
    fps: float
    scene_changes: list[float]

@dataclass
class TranscriptSegment:
    start: float             # å¼€å§‹æ—¶é—´ (ç§’)
    end: float               # ç»“æŸæ—¶é—´ (ç§’)
    text: str                # æ–‡æœ¬å†…å®¹

@dataclass
class VideoTranscript:      # M1
    video_path: Path
    title: str
    language: str
    segments: list[TranscriptSegment]
    optimized_text: str      # AI ä¼˜åŒ–åçš„æ–‡ç¨¿

@dataclass
class KeyFrame:
    timestamp: float         # æ—¶é—´ç‚¹ (ç§’)
    source: str              # æ¥æº: scene_change / interval / transcript_hint
    reason: str              # é€‰æ‹©åŸå› 

@dataclass
class KeyFrames:            # M2
    video_path: Path
    frames: list[KeyFrame]

@dataclass
class ImageDescription:
    timestamp: float
    image_path: Path
    description: str         # AI æè¿°
    key_elements: list[str]
    related_transcript: str

@dataclass
class ImageDescriptions:    # M3
    descriptions: list[ImageDescription]

@dataclass
class Chapter:
    id: int
    title: str
    start_time: float
    end_time: float
    summary: str
    key_points: list[str]
    cleaned_transcript: str
    visual_timestamp: Optional[float]
    visual_reason: Optional[str]

@dataclass
class Document:
    title: str
    chapters: list[Chapter]
```

## 4. ç¼“å­˜æœºåˆ¶

Stage 2 å®ç°äº†ä¸¤çº§ç¼“å­˜ï¼š

```
test_outputs/temp/cache/stage2/
â””â”€â”€ {video_name}_{hash}_{model}_{lang}_raw.json
```

ç¼“å­˜å†…å®¹ï¼š
- `video_hash`: è§†é¢‘æ–‡ä»¶å‰ 1MB çš„ SHA256ï¼ˆç”¨äºæ£€æµ‹è§†é¢‘å˜åŒ–ï¼‰
- `segments`: Whisper åŸå§‹è½¬å½•ç»“æœ
- `model`: ä½¿ç”¨çš„æ¨¡å‹åç§°
- `language`: è¯­è¨€ä»£ç 

ä½¿ç”¨ `--no-cache` è·³è¿‡ç¼“å­˜ï¼Œä½¿ç”¨ `--clear-cache` å¼ºåˆ¶é‡æ–°è½¬å½•ã€‚

## 5. å…³é”®è®¾è®¡å†³ç­–

### 5.1 Text-First è®¾è®¡

- **æ ¸å¿ƒåŸåˆ™**ï¼šæ–‡å­—å†…å®¹æ˜¯ä¸»ä½“ï¼Œå›¾ç‰‡æ˜¯è¾…åŠ©
- **å®ç°æ–¹å¼**ï¼š
  - ä¼˜å…ˆä½¿ç”¨ Whisper è½¬å½•çš„å®Œæ•´å†…å®¹
  - AI ç« èŠ‚åˆ’åˆ†åŸºäºæ–‡å­—å†…å®¹
  - å›¾ç‰‡ä»…ç”¨äºè¡¥å……æ–‡å­—æ— æ³•è¡¨è¾¾çš„ä¿¡æ¯

### 5.2 Prompt æ–‡ä»¶åŒ–

æ‰€æœ‰ AI Prompt æå–åˆ° `prompts/` ç›®å½•ï¼š
- `transcript_optimization.md` - Stage 2c: æ–‡ç¨¿ä¼˜åŒ–
- `image_analysis.md` - Stage 5: å›¾åƒåˆ†æ  
- `document_merge.md` - Stage 6: å›¾æ–‡èåˆ

ä½¿ç”¨ YAML Frontmatter å®šä¹‰å‚æ•°ï¼š
```yaml
---
name: transcript-optimization
version: "1.0.0"
models: [kimi-k2.5]
parameters:
  temperature: 1
variables: [title, raw_text]
---
```

### 5.3 æ™ºèƒ½å›¾ç‰‡ç­›é€‰

**ç›®çš„**ï¼šå‡å°‘ä¸å¿…è¦çš„ API è°ƒç”¨ï¼Œé™ä½æˆæœ¬å’Œæ—¶é—´

| ç­›é€‰å±‚çº§ | æ–¹æ³• | èŠ‚çœç‡ |
|---------|------|-------|
| ç¬¬ä¸€å±‚ | æ—¶é—´æˆ³å»é‡ | 20% |
| ç¬¬äºŒå±‚ | OCR æ–‡å­—æ£€æµ‹ | 30% |
| ç¬¬ä¸‰å±‚ | è¯­ä¹‰ç›¸å…³æ€§æ£€æŸ¥ | 20% |

### 5.4 æ¨¡å‹é€‰æ‹©

| ç”¨é€” | æ¨¡å‹ | ç†ç”± |
|-----|------|------|
| è¯­éŸ³è¯†åˆ« | whisper.cpp (local) | å…è´¹ã€ç¦»çº¿ã€ä¿æŠ¤éšç§ |
| æ–‡æœ¬ç”Ÿæˆ | kimi-k2.5 | ä¸­æ–‡ç†è§£èƒ½åŠ›å¼ºã€ä¸Šä¸‹æ–‡é•¿ |
| å›¾åƒç†è§£ | kimi-k2.5 | æ”¯æŒè§†è§‰ã€æ€§ä»·æ¯”é«˜ |

### 5.5 é”™è¯¯å¤„ç†ç­–ç•¥

- **å¯æ¢å¤é”™è¯¯**ï¼šè·³è¿‡å½“å‰æ­¥éª¤ï¼Œç»§ç»­å¤„ç†ï¼ˆå¦‚å•å¼ å›¾ç‰‡åˆ†æå¤±è´¥ï¼‰
- **å…³é”®é”™è¯¯**ï¼šç»ˆæ­¢å¤„ç†ï¼Œè¿”å›é”™è¯¯ä¿¡æ¯ï¼ˆå¦‚è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨ï¼‰
- **é™çº§ç­–ç•¥**ï¼šå¦‚æœ AI æœåŠ¡ä¸å¯ç”¨ï¼Œä»è¾“å‡ºåŸºç¡€è½¬å½•å’Œå…³é”®å¸§

## 6. é…ç½®ä½“ç³»

é…ç½®ä¼˜å…ˆçº§ï¼ˆä»é«˜åˆ°ä½ï¼‰ï¼š

1. **å‘½ä»¤è¡Œå‚æ•°**
   ```bash
   uv run python -m video2markdown process --keyframe-interval 60
   ```

2. **ç¯å¢ƒå˜é‡**
   ```bash
   export KIMI_KEYFRAME_INTERVAL=60
   ```

3. **.env æ–‡ä»¶**
   ```
   KIMI_KEYFRAME_INTERVAL=60
   ```

4. **é»˜è®¤å€¼**
   - ä»£ç ä¸­å®šä¹‰çš„é»˜è®¤å€¼

## 7. æ‰©å±•æ€§è®¾è®¡

### 7.1 æ·»åŠ æ–°çš„ Stage

Stage è®¾è®¡éµå¾ªç»Ÿä¸€æ¥å£ï¼š

```python
def stageX_process(input_data: InputType, ...) -> OutputType:
    """Stage X: å¤„ç†æè¿°.
    
    è¾“å…¥: ...
    è¾“å‡º: ...
    """
    print(f"[Stage X] å¤„ç†...")
    # å¤„ç†é€»è¾‘
    return output
```

### 7.2 æ·»åŠ æ–°çš„ ASR æä¾›å•†

åœ¨ `stage2_transcribe.py` ä¸­æ‰©å±•ï¼š

```python
def transcribe_audio(audio_path: Path, model_path: Path, language: str) -> list[TranscriptSegment]:
    if settings.asr_provider == "local":
        return _transcribe_with_whisper(audio_path, model_path, language)
    elif settings.asr_provider == "openai":
        return _transcribe_with_openai(audio_path, language)
    # æ–°å¢
    elif settings.asr_provider == "azure":
        return _transcribe_with_azure(audio_path, language)
```

### 7.3 æ·»åŠ æ–°çš„è¾“å‡ºæ ¼å¼

åœ¨ `stage7_render.py` ä¸­æ‰©å±•ï¼š

```python
def render_document(document: Document, format: str = "markdown") -> str:
    if format == "markdown":
        return _render_markdown(document)
    elif format == "html":
        return _render_html(document)
    # æ–°å¢
    elif format == "pdf":
        return _render_pdf(document)
```

---

*æœ€åæ›´æ–°: 2026-02-12 - æ›´æ–°ä¸º 7-Stage æ¶æ„*
