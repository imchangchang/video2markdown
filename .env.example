# Video2Markdown 配置文件
# 复制为 .env 并填入你的 API Key

# ============================================
# LLM API 配置（必需）
# ============================================
# 支持: Kimi, DeepSeek, OpenAI 等兼容 OpenAI API 格式的服务
# 从对应平台获取 API Key
VIDEO2MD_API_KEY=your-api-key

# 文本生成模型
# 示例: kimi-k2.5, deepseek-chat, gpt-4o
VIDEO2MD_MODEL=kimi-k2.5

# 视觉模型（用于图片分析）
# 示例: kimi-k2.5, gpt-4o-vision
VIDEO2MD_VISION_MODEL=kimi-k2.5

# API 基础 URL
# 示例: https://api.moonshot.cn/v1 (Kimi)
#       https://api.deepseek.com/v1 (DeepSeek)
#       https://api.openai.com/v1 (OpenAI)
VIDEO2MD_BASE_URL=https://api.moonshot.cn/v1

# ============================================
# 输出语言配置
# ============================================
# 指定最终文稿的输出语言
# 支持: zh(中文), en(英文), ja(日文), ko(韩文) 等
# AI 会自动将转录内容翻译/优化为目标语言
VIDEO2MD_OUTPUT_LANGUAGE=zh

# ============================================
# Whisper 语音转文字配置
# ============================================
# ASR 提供商: local 或 openai
# local: 使用本地 whisper.cpp（推荐，免费）
# openai: 使用 OpenAI Whisper API（需要 API Key 和网络）
VIDEO2MD_ASR_PROVIDER=local

# 本地模型路径（ASR_PROVIDER=local 时有效）
# 支持的模型: ggml-tiny, ggml-base, ggml-small, ggml-medium
VIDEO2MD_WHISPER_LOCAL_MODEL=models/ggml-medium-q8_0.bin

# ============================================
# 并发配置
# ============================================
# LLM API 最大并发数（根据你的 API 限流设置）
VIDEO2MD_API_MAX_CONCURRENCY=100

# 图片分析并发数（建议不超过 API_MAX_CONCURRENCY）
VIDEO2MD_IMAGE_MAX_CONCURRENCY=20

# ============================================
# 处理参数配置
# ============================================
# 关键帧采样间隔（秒）
VIDEO2MD_KEYFRAME_INTERVAL=30

# ============================================
# LLM API 定价配置（用于费用计算，单位：元/百万 tokens）
# ============================================
# 根据你的模型提供商填写对应价格
# 从对应平台获取最新价格
VIDEO2MD_LLM_PRICE_INPUT_PER_1M=4.0
VIDEO2MD_LLM_PRICE_OUTPUT_PER_1M=21.0
