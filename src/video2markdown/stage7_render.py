"""Stage 7: Markdown æ¸²æŸ“.

è¾“å…¥: Document + ImageDescriptions (M3)
è¾“å‡º: Markdown æ–‡ä»¶

è¾“å‡ºç»“æ„:
    {title}/
    â”œâ”€â”€ {title}.md           # æœ€ç»ˆæ–‡æ¡£
    â”œâ”€â”€ {title}_word.md      # è§†é¢‘æ–‡å­—ç¨¿
    â”œâ”€â”€ {title}.srt          # å­—å¹•æ–‡ä»¶
    â””â”€â”€ images/              # å…³é”®é…å›¾
        â”œâ”€â”€ frame_0001_15.5s.jpg
        â”œâ”€â”€ frame_0001_15.5s.txt  # é…å›¾è¯´æ˜
        â””â”€â”€ ...
"""

import shutil
from pathlib import Path
from typing import Optional

from video2markdown.models import Document, ImageDescriptions, VideoTranscript


def render_markdown(
    document: Document,
    transcript: VideoTranscript,
    descriptions: ImageDescriptions,
    output_dir: Path,
) -> Path:
    """æ¸²æŸ“ Markdown æ–‡æ¡£.
    
    Args:
        document: æ–‡æ¡£ç»“æ„
        transcript: è§†é¢‘æ–‡å­—ç¨¿ (M1)
        descriptions: é…å›¾è¯´æ˜ (M3)
        output_dir: è¾“å‡ºç›®å½•
        
    Returns:
        ä¸»æ–‡æ¡£è·¯å¾„
    """
    print(f"[Stage 7] Markdown æ¸²æŸ“")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•ç»“æ„
    doc_dir = output_dir / document.title
    doc_dir.mkdir(parents=True, exist_ok=True)
    
    # ä½¿ç”¨ç»Ÿä¸€çš„ images/ ç›®å½•å­˜æ”¾é…å›¾ï¼Œé¿å…ç‰¹æ®Šå­—ç¬¦è·¯å¾„é—®é¢˜
    frames_dir = doc_dir / "images"
    frames_dir.mkdir(exist_ok=True)
    
    # 1. æ¸²æŸ“ä¸»æ–‡æ¡£
    main_doc = _render_main_document(document, descriptions)
    main_path = doc_dir / f"{document.title}.md"
    main_path.write_text(main_doc, encoding="utf-8")
    print(f"  âœ“ ä¸»æ–‡æ¡£: {main_path}")
    
    # 2. ä¿å­˜æ–‡å­—ç¨¿
    word_path = doc_dir / f"{document.title}_word.md"
    word_path.write_text(transcript.to_word_document(), encoding="utf-8")
    print(f"  âœ“ æ–‡å­—ç¨¿: {word_path}")
    
    # 3. ä¿å­˜å­—å¹•
    srt_path = doc_dir / f"{document.title}.srt"
    srt_path.write_text(transcript.to_srt(), encoding="utf-8")
    print(f"  âœ“ å­—å¹•: {srt_path}")
    
    # 4. å¤åˆ¶é…å›¾å’Œè¯´æ˜
    _copy_frames_with_descriptions(descriptions, frames_dir)
    
    return main_path


def _render_main_document(
    document: Document,
    descriptions: ImageDescriptions,
) -> str:
    """æ¸²æŸ“ä¸» Markdown æ–‡æ¡£."""
    lines = []
    
    # æ ‡é¢˜
    lines.append(f"# {document.title}")
    lines.append("")
    lines.append("*AI æ•´ç†çš„è§†é¢‘å†…å®¹*")
    lines.append("")
    
    # ç›®å½•
    lines.append("## ç›®å½•")
    for ch in document.chapters:
        anchor = f"chapter-{ch.id}"
        lines.append(f"{ch.id}. [{ch.title}](#{anchor})")
    lines.append("")
    lines.append("---")
    lines.append("")
    
    # ç« èŠ‚å†…å®¹
    for ch in document.chapters:
        anchor = f"chapter-{ch.id}"
        lines.append(f"<a id='{anchor}'></a>")
        lines.append(f"## {ch.id}. {ch.title}")
        lines.append("")
        lines.append(f"**æ—¶é—´:** [{ch.start_time} - {ch.end_time}]")
        lines.append("")
        
        # æ‘˜è¦
        lines.append("### å†…å®¹æ‘˜è¦")
        lines.append(ch.summary)
        lines.append("")
        
        # å…³é”®è¦ç‚¹
        if ch.key_points:
            lines.append("### å…³é”®è¦ç‚¹")
            for point in ch.key_points:
                lines.append(f"- {point}")
            lines.append("")
        
        # é…å›¾ (å¦‚æœæœ‰)
        if ch.visual_timestamp:
            desc = descriptions.get_by_timestamp(ch.visual_timestamp)
            if desc:
                frame_file = desc.image_path.name
                lines.append("### ç›¸å…³ç”»é¢")
                # ä½¿ç”¨ç›¸å¯¹è·¯å¾„ images/ ç›®å½•ï¼Œé¿å…ç‰¹æ®Šå­—ç¬¦å’Œç©ºæ ¼é—®é¢˜
                lines.append(f"![{ch.visual_timestamp}s](images/{frame_file})")
                lines.append("")
                lines.append("**ç”»é¢å†…å®¹:**")
                lines.append(f"> {desc.description}")
                lines.append("")
                if desc.key_elements:
                    lines.append(f"**å…³é”®å…ƒç´ :** {', '.join(desc.key_elements)}")
                    lines.append("")
        
        # åŸæ–‡
        if ch.cleaned_transcript:
            lines.append("### åŸæ–‡è®°å½•")
            lines.append("<details>")
            lines.append("<summary>ğŸ“„ æŸ¥çœ‹åŸå§‹è½¬å½•</summary>")
            lines.append("")
            lines.append(ch.cleaned_transcript)
            lines.append("</details>")
            lines.append("")
        
        lines.append("---")
        lines.append("")
    
    return "\n".join(lines)


def _copy_frames_with_descriptions(
    descriptions: ImageDescriptions,
    frames_dir: Path,
) -> None:
    """å¤åˆ¶é…å›¾å’Œè¯´æ˜æ–‡ä»¶."""
    for desc in descriptions.descriptions:
        if not desc.image_path.exists():
            continue
        
        # å¤åˆ¶å›¾ç‰‡
        dest_image = frames_dir / desc.image_path.name
        shutil.copy2(desc.image_path, dest_image)
        
        # ä¿å­˜è¯´æ˜
        desc_file = frames_dir / f"{desc.image_path.stem}.txt"
        desc_content = f"æ—¶é—´æˆ³: {desc.timestamp}s\n\n"
        desc_content += f"æè¿°: {desc.description}\n\n"
        desc_content += f"å…³é”®å…ƒç´ : {', '.join(desc.key_elements)}\n\n"
        desc_content += f"ç›¸å…³æ–‡å­—ç¨¿:\n{desc.related_transcript[:500]}..."
        desc_file.write_text(desc_content, encoding="utf-8")
    
    print(f"  âœ“ é…å›¾: {frames_dir} ({len(descriptions.descriptions)} å¼ )")


# CLI å…¥å£
if __name__ == "__main__":
    import sys
    from video2markdown.stage1_analyze import analyze_video
    from video2markdown.stage2_transcribe import transcribe_video
    from video2markdown.stage3_keyframes import extract_candidate_frames
    from video2markdown.stage4_filter import filter_keyframes
    from video2markdown.stage5_analyze_images import analyze_images
    from video2markdown.stage6_generate import generate_document
    
    if len(sys.argv) < 3:
        print("ç”¨æ³•: python -m video2markdown.stage7_render <è§†é¢‘æ–‡ä»¶> <æ¨¡å‹è·¯å¾„>")
        sys.exit(1)
    
    video_path = Path(sys.argv[1])
    model_path = Path(sys.argv[2])
    
    # è¿è¡Œå®Œæ•´æµç¨‹
    video_info = analyze_video(video_path)
    transcript = transcribe_video(video_path, video_info, model_path)
    candidates = extract_candidate_frames(video_path, video_info)
    keyframes = filter_keyframes(video_path, candidates, transcript)
    
    frames_dir = Path("testbench/output") / f"{video_path.stem}_frames"
    descriptions = analyze_images(video_path, keyframes, transcript, frames_dir)
    document = generate_document(transcript, keyframes, descriptions)
    
    # è¿è¡Œ Stage 7
    output_dir = Path("testbench/output")
    result_path = render_markdown(document, transcript, descriptions, output_dir)
    
    print(f"\nâœ… å®Œæ•´è¾“å‡ºå·²ä¿å­˜åˆ°: {result_path.parent}")
