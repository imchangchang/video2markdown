"""Stage 6: AI æ–‡æ¡£ç”Ÿæˆ.

è¾“å…¥: M1 (VideoTranscript) + M2 (KeyFrames) + M3 (ImageDescriptions)
è¾“å‡º: Document (æ–‡æ¡£ç»“æ„)

æµç¨‹:
    1. å°† M1 çš„æ–‡å­—ç¨¿å‘é€ç»™ AI
    2. AI ç”Ÿæˆç« èŠ‚ç»“æ„
    3. æ ¹æ® M2/M3 å°†å›¾ç‰‡å…³è”åˆ°ç« èŠ‚
    4. ç”Ÿæˆæœ€ç»ˆæ–‡æ¡£ç»“æ„
"""

import json
from pathlib import Path
from typing import Optional

from openai import OpenAI

from video2markdown.config import settings
from video2markdown.models import (
    Chapter, Document, ImageDescriptions, KeyFrames, VideoTranscript
)
from video2markdown.stage5_analyze_images import _load_prompt_with_meta


def generate_document(
    transcript: VideoTranscript,
    keyframes: KeyFrames,
    descriptions: ImageDescriptions,
    title: Optional[str] = None,
) -> Document:
    """AI å›¾æ–‡èåˆç”Ÿæˆ.
    
    å°† M1 (AIä¼˜åŒ–æ–‡ç¨¿)ã€M2 (å…³é”®é…å›¾)ã€M3 (é…å›¾è¯´æ˜) èåˆä¸ºæœ€ç»ˆæ–‡æ¡£ç»“æ„.
    
    Args:
        transcript: è§†é¢‘æ–‡ç¨¿ (M1ï¼Œå·²ä¼˜åŒ–)
        keyframes: å…³é”®é…å›¾ (M2)
        descriptions: é…å›¾è¯´æ˜ (M3)
        title: æ–‡æ¡£æ ‡é¢˜
        
    Returns:
        Document æ–‡æ¡£ç»“æ„
    """
    print(f"[Stage 6] AI å›¾æ–‡èåˆç”Ÿæˆ")
    
    client = OpenAI(**settings.get_client_kwargs())
    doc_title = title or transcript.title
    
    # å‡†å¤‡è¾“å…¥æ•°æ®
    input_data = _prepare_input(transcript, keyframes, descriptions)
    
    print(f"  è°ƒç”¨ AI èåˆ M1 + M2 + M3...")
    
    # åŠ è½½ prompt æ¨¡æ¿
    prompt_path = settings.prompts_dir / "document_merge.md"
    if not prompt_path.exists():
        raise FileNotFoundError(f"Prompt æ–‡ä»¶ä¸å­˜åœ¨: {prompt_path}")
    
    system_msg, user_template, api_params = _load_prompt_with_meta(prompt_path)
    
    # å¡«å……æ¨¡æ¿å˜é‡ï¼ˆä½¿ç”¨å®‰å…¨æ›¿æ¢ï¼Œé¿å… JSON ä¸­çš„ { è¢«å½“ä½œæ ¼å¼æ ‡è®°ï¼‰
    user_content = user_template
    user_content = user_content.replace("{title}", input_data["title"])
    user_content = user_content.replace("{m1_text}", input_data["m1_text"])
    user_content = user_content.replace("{images}", json.dumps(input_data["images"], ensure_ascii=False))
    
    # è°ƒç”¨ AI - ä»»åŠ¡æ˜¯åœ¨ M1 çš„åˆé€‚ä½ç½®æ’å…¥é…å›¾
    response = client.chat.completions.create(
        model=settings.model,
        messages=[
            {
                "role": "system", 
                "content": system_msg
            },
            {
                "role": "user",
                "content": user_content
            }
        ],
        **api_params,
    )
    
    # æ˜¾ç¤º Token ç”¨é‡å’Œä»·æ ¼
    _print_usage_info(response)
    
    # è§£æå“åº”
    content = response.choices[0].message.content
    doc_data = _parse_response(content)
    
    # åˆ›å»º Document
    chapters = []
    for i, ch in enumerate(doc_data.get("chapters", []), 1):
        chapter = Chapter(
            id=i,
            title=ch.get("title", f"ç« èŠ‚ {i}"),
            start_time=ch.get("start_time", "00:00:00"),
            end_time=ch.get("end_time", "00:00:00"),
            summary=ch.get("summary", ""),
            key_points=ch.get("key_points", []),
            cleaned_transcript=ch.get("cleaned_transcript", ""),
            visual_timestamp=ch.get("visual_timestamp"),
            visual_reason=ch.get("visual_reason"),
        )
        chapters.append(chapter)
    
    print(f"  âœ“ ç”Ÿæˆ {len(chapters)} ä¸ªç« èŠ‚")
    
    return Document(
        title=doc_data.get("title", doc_title),
        chapters=chapters,
    )


def _print_usage_info(response) -> None:
    """æ‰“å° API ç”¨é‡å’Œä»·æ ¼ä¿¡æ¯ï¼Œå¹¶æ›´æ–°å…¨å±€ç»Ÿè®¡."""
    if not hasattr(response, 'usage') or response.usage is None:
        return
    
    usage = response.usage
    prompt_tokens = getattr(usage, 'prompt_tokens', 0)
    completion_tokens = getattr(usage, 'completion_tokens', 0)
    total_tokens = getattr(usage, 'total_tokens', 0)
    
    if total_tokens == 0:
        return
    
    # æ›´æ–°å…¨å±€ç»Ÿè®¡
    from video2markdown.stats import get_stats
    get_stats().add(prompt_tokens, completion_tokens)
    
    # Kimi K2.5 ä»·æ ¼ (2025-02)
    # è¾“å…¥: Â¥4.8 / ç™¾ä¸‡ tokens (çº¦ $0.60)
    # è¾“å‡º: Â¥20 / ç™¾ä¸‡ tokens (çº¦ $2.50)
    INPUT_PRICE_PER_1M = 4.8  # äººæ°‘å¸
    OUTPUT_PRICE_PER_1M = 20.0  # äººæ°‘å¸
    
    input_cost = (prompt_tokens / 1_000_000) * INPUT_PRICE_PER_1M
    output_cost = (completion_tokens / 1_000_000) * OUTPUT_PRICE_PER_1M
    total_cost = input_cost + output_cost
    
    print(f"  ğŸ“Š Token ç”¨é‡:")
    print(f"     è¾“å…¥: {prompt_tokens:,} tokens")
    print(f"     è¾“å‡º: {completion_tokens:,} tokens")
    print(f"     æ€»è®¡: {total_tokens:,} tokens")
    print(f"  ğŸ’° é¢„ä¼°è´¹ç”¨: Â¥{total_cost:.4f} (è¾“å…¥Â¥{input_cost:.4f} + è¾“å‡ºÂ¥{output_cost:.4f})")


def _prepare_input(
    transcript: VideoTranscript,
    keyframes: KeyFrames,
    descriptions: ImageDescriptions,
) -> dict:
    """å‡†å¤‡ AI è¾“å…¥æ•°æ®."""
    # é…å›¾ä¿¡æ¯
    images_data = []
    for desc in descriptions.descriptions:
        images_data.append({
            "timestamp": desc.timestamp,
            "description": desc.description,
            "key_elements": desc.key_elements,
        })
    
    return {
        "title": transcript.title,
        "m1_text": transcript.optimized_text,  # ä½¿ç”¨ AI ä¼˜åŒ–åçš„æ–‡ç¨¿
        "images": images_data,
    }


def _parse_response(content: str) -> dict:
    """è§£æ AI å“åº”ï¼Œå¢å¼ºé”™è¯¯å¤„ç†."""
    import re
    
    original_content = content.strip()
    
    # å¤„ç† markdown ä»£ç å—
    if "```json" in content:
        start = content.find("```json") + 7
        end = content.find("```", start)
        if end == -1:
            end = len(content)
        content = content[start:end].strip()
    elif "```" in content:
        start = content.find("```") + 3
        end = content.find("```", start)
        if end == -1:
            end = len(content)
        content = content[start:end].strip()
    
    # å°è¯•è§£æ JSON
    try:
        return json.loads(content)
    except json.JSONDecodeError as e:
        print(f"  âš ï¸  JSON è§£æå¤±è´¥: {e}")
        print(f"  å°è¯•ä¿®å¤...")
        
        # å°è¯•æå– JSON å¯¹è±¡ï¼ˆæŸ¥æ‰¾æœ€å¤–å±‚çš„èŠ±æ‹¬å·å†…å®¹ï¼‰
        try:
            # æŸ¥æ‰¾ç¬¬ä¸€ä¸ª { å’Œæœ€åä¸€ä¸ª }
            start_idx = content.find('{')
            end_idx = content.rfind('}')
            if start_idx != -1 and end_idx != -1 and start_idx < end_idx:
                json_content = content[start_idx:end_idx+1]
                return json.loads(json_content)
        except Exception:
            pass
        
        # å¦‚æœä»ç„¶å¤±è´¥ï¼Œè¿”å›ä¸€ä¸ªåŸºæœ¬çš„ç»“æ„
        print(f"  âš ï¸  æ— æ³•è§£æ AI å“åº”ï¼Œä½¿ç”¨é»˜è®¤ç»“æ„")
        # ä¿å­˜åŸå§‹å“åº”ç”¨äºè°ƒè¯•
        debug_path = Path("test_outputs/temp/stage6_debug_response.txt")
        debug_path.parent.mkdir(parents=True, exist_ok=True)
        debug_path.write_text(original_content, encoding="utf-8")
        print(f"  åŸå§‹å“åº”å·²ä¿å­˜åˆ°: {debug_path}")
        
        return {
            "title": "è§£æå¤±è´¥ - ä½¿ç”¨é»˜è®¤ç»“æ„",
            "chapters": []
        }


# CLI å…¥å£
if __name__ == "__main__":
    import sys
    from video2markdown.stage1_analyze import analyze_video
    from video2markdown.stage2_transcribe import transcribe_video
    from video2markdown.stage3_keyframes import extract_candidate_frames
    from video2markdown.stage4_filter import filter_keyframes
    from video2markdown.stage5_analyze_images import analyze_images
    
    if len(sys.argv) < 3:
        print("ç”¨æ³•: python -m video2markdown.stage6_generate <è§†é¢‘æ–‡ä»¶> <æ¨¡å‹è·¯å¾„>")
        sys.exit(1)
    
    video_path = Path(sys.argv[1])
    model_path = Path(sys.argv[2])
    
    # è¿è¡Œå‰ç½®é˜¶æ®µ
    video_info = analyze_video(video_path)
    transcript = transcribe_video(video_path, video_info, model_path)
    candidates = extract_candidate_frames(video_path, video_info)
    keyframes = filter_keyframes(video_path, candidates, transcript)
    
    frames_dir = Path("testbench/output") / f"{video_path.stem}_frames"
    descriptions = analyze_images(video_path, keyframes, transcript, frames_dir)
    
    # è¿è¡Œ Stage 6
    document = generate_document(transcript, keyframes, descriptions)
    
    print(f"\næ–‡æ¡£ç»“æ„:")
    print(f"  æ ‡é¢˜: {document.title}")
    for ch in document.chapters:
        visual = f" [é…å›¾@{ch.visual_timestamp:.0f}s]" if ch.visual_timestamp else ""
        print(f"  - {ch.title}{visual}")
